inference_gpu_ids = [0]
trainer_gpu_ids = [1]

max_steps = 25
seq_len = 2048

[ckpt]
resume_step = 20

[model]
name = "PrimeIntellect/Qwen3-0.6B-Reverse-Text-SFT"

[trainer.optim]
lr = 3e-6

[orchestrator]
batch_size = 128
rollouts_per_example = 16

[orchestrator.sampling]
max_tokens = 128

[[orchestrator.env]]
id = "reverse-text"

[inference]